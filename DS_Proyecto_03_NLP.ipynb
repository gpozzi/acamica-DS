{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2GRQnxMzISE_"
   },
   "source": [
    "# Proyecto 03 - Procesamiento del Lenguaje Natural\n",
    "\n",
    "## Dataset: The Multilingual Amazon Reviews Corpus\n",
    "\n",
    "**Recuerda descargar el dataset de [aquí](https://github.com/kang205/SASRec). Es un archivo .zip que contiene tres documentos. Más información sobre el dataset [aquí](https://registry.opendata.aws/amazon-reviews-ml/). Es importante que tengas en cuenta la [licencia](https://docs.opendata.aws/amazon-reviews-ml/license.txt) de este dataset.**\n",
    "\n",
    "### Exploración de datos y Procesamiento del Lenguaje Natural\n",
    "\n",
    "Dedícale un buen tiempo a hacer un Análisis Exploratorio de Datos. Considera que hasta que no hayas aplicado las herramientas de Procesamiento del Lenguaje Natural vistas, será difícil completar este análisis. Elige preguntas que creas que puedas responder con este dataset. Por ejemplo, ¿qué palabras están asociadas a calificaciones positivas y qué palabras a calificaciones negativas?\n",
    "\n",
    "### Machine Learning\n",
    "\n",
    "Implementa un modelo que, dada la crítica de un producto, asigne la cantidad de estrellas correspondiente. **Para pensar**: ¿es un problema de Clasificación o de Regresión?\n",
    "\n",
    "1. Haz todas las transformaciones de datos que consideres necesarias. Justifica.\n",
    "1. Evalúa de forma apropiada sus resultados. Justifica la métrica elegida.\n",
    "1. Elige un modelo benchmark y compara tus resultados con este modelo.\n",
    "1. Optimiza los hiperparámetros de tu modelo.\n",
    "1. Intenta responder la pregunta: ¿Qué información está usando el modelo para predecir?\n",
    "\n",
    "**Recomendación:** si no te resulta conveniente trabajar en español con NLTK, te recomendamos que explores la librería [spaCy](https://spacy.io/).\n",
    "\n",
    "### Para pensar, investigar y, opcionalmente, implementar\n",
    "1. ¿Valdrá la pena convertir el problema de Machine Learning en un problema binario? Es decir, asignar únicamente las etiquetas Positiva y Negativa a cada crítica y hacer un modelo que, en lugar de predecir las estrellas, prediga esa etiqueta. Pensar en qué situación puede ser útil. ¿Esperas que el desempeño sea mejor o peor?\n",
    "1. ¿Hay algo que te gustaría investigar o probar?\n",
    "\n",
    "### **¡Tómate tiempo para investigar y leer mucho!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1GFwraSISFB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import es_core_news_sm\n",
    "\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('dataset_es_dev.json',lines=True)\n",
    "df_test = pd.read_json('dataset_es_test.json',lines=True)\n",
    "df_train = pd.read_json('dataset_es_train.json',lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A - Exploración de datos y Procesamiento del Lenguaje Natural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto el dataset de formación como el de prueba cuentan con <code>5000 reviews</code>, mientras que el de entrenamiento posee <code>200.000 instancias</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df_test.shape)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos cuentan con 7 atributos:\n",
    "- ID de reseña\n",
    "- ID de producto\n",
    "- ID de evaluador\n",
    "- Estrellas\n",
    "- Cuerpo de reseña\n",
    "- Título de reseña\n",
    "- Idioma\n",
    "- Categoría de producto\n",
    "\n",
    "Ninguno de los cuales posee valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "print(df_test.info())\n",
    "print(df_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La totalidad de las reseñas se encuentran en idioma español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['language'].unique())\n",
    "print(df_test['language'].unique())\n",
    "print(df_train['language'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que para explorar el dataset completo resulta difícil trabajar con los 3 por separado, los concatenaré a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon = pd.concat([df,df_test,df_train],axis=0)\n",
    "df_amazon.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedo observar del siguiente gráfico que cada puntaje posee la misma cantidad de reseñas asociadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'stars', data = df_amazon)\n",
    "plt.ylabel('Cantidad de reseñas')\n",
    "plt.xlabel('Puntaje (estrellas)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Existen',str(len(df_amazon['product_category'].unique())),'categorías únicas en el presente dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que predominan las reseñas de productos línea **hogar** e **inalámbricos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "sns.countplot(y = 'product_category', \n",
    "              data = df_amazon,  \n",
    "              order = df_amazon.product_category.value_counts().index)\n",
    "plt.ylabel('Categoría',size=13)\n",
    "plt.xlabel('Cantidad de reviews')\n",
    "plt.tick_params(axis='y', labelsize=13)\n",
    "plt.title('Categorías de los diferentes productos', size=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de las reseñas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon['review_entero'] = df_amazon['review_body']+ ' ' + df_amazon['review_title']\n",
    "df_amazon.reset_index(inplace=True,drop=True)\n",
    "df_amazon.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo las palabras comunes (stopwords) en español para luego filtrar las distintas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que aplica procesamiento del lenguaje natural a palabras en español\n",
    "nlp = es_core_news_sm.load()\n",
    "\n",
    "stop_words = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A través de la siguiente función se aplica <code>**normalizado**</code> al texto de cada fila. Esto incluye:\n",
    "- <code>Tokenizado</code> (separación de una secuencia de palabras en partes, almacenadas en una lista)\n",
    "- Todas las palabras pasan a ser minúsculas\n",
    "- Se eliminan comas, puntos y palabras de 1 letra (por ejemplo \"y\", \"a\", etc)\n",
    "- Se quitan las <code>stopwords</code>. Estas son palabras que carecen de significado por sí solas, como preposiciones, artículos, conjunciones, pronombres, etc.\n",
    "- <code>Stemming</code> y <code>lemmatizado</code>. En el **stemming** se recorta el principio o el final de la palabra que suele ser común a las diferentes conjugaciones (por ejemplo, palabras \"niñez\", o \"niñas\" al ser stemmizadas quedarían \"niñ\"), mientras que el **lemmatizado** tiene en cuenta el análisis morfológico de la palabra (por ejemplo, palabras como \"estudiando\" o \"estudios\" serían transformadas a \"estudio\")\n",
    "\n",
    "El objetivo de este preprocesamiento, que reducirá el ruido del texto al eliminar las formas infleccionales y a veces derivacionalmente relacionadas a una base común*, es facilitar el posterior análisis de cada reseña mediante algoritmos de clasificación. De esta forma, se podrán predecir con mayor precisión la cantidad de estrellas que daría un usuario dada una reseña\n",
    "\n",
    "*\"**Stemming and lemmatization\", Stanford, Cambridge University Press, 2008, https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html**\n",
    "\n",
    "\n",
    "McNary, Dave. “Keanu Reeves, Alex Winter Returning for ‘Bill and Ted Face the Music.’” Variety, Penske Media Corporation, 8 May 2018, variety.com/2018/film/news/bill-and-ted-3-keanu-reeves-alex-winter-1202802946/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar(texto):\n",
    "    reseña_tk = nltk.RegexpTokenizer('\\w+').tokenize(texto)\n",
    "    reseña_tk_minusculas = [word.lower() for word in reseña_tk if word.lower() not in stop_words]\n",
    "    reseña_limpia = ' '.join(reseña_tk_minusculas)\n",
    "    reseña_limpia = nlp(reseña_limpia)\n",
    "    reseña_lemm = [word.lemma_ for word in reseña_limpia]\n",
    "    reseña_lemm = [t for t in reseña_lemm if len(t)>1]\n",
    "    return reseña_lemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procesar(df_amazon.review_entero[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def procesar(texto):\n",
    "#    palabras = []\n",
    "#    doc = nlp(texto)\n",
    "#    for sent in doc.sentences:\n",
    "#        for word in sent.words:\n",
    "#            palabras.append(word.lemma)\n",
    "#    palabras = list(filter(lambda x: x != \",\" and x != \".\", palabras))\n",
    "#    palabras = [item for item in palabras if item not in stopwords]\n",
    "#    return palabras\n",
    "#procesar(df_amazon['review_entero'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon['review_entero_tk'] = df_amazon.apply(lambda row: procesar(row['review_entero']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon.to_excel('Preprocesado.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon = pd.read_excel('Preprocesado.xlsx').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_amazon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a048db3c24b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_amazon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_amazon' is not defined"
     ]
    }
   ],
   "source": [
    "df_amazon.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 palabras más comunes para críticas de 1 estrellas\n",
      "  Palabras  Frecuencia\n",
      "0        '     1033814\n",
      "1        r      477573\n",
      "2        ,      474913\n",
      "3               474913\n",
      "4        a      437064\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for x in range(1,6):\n",
    "    tokenizado_df = df_amazon[df_amazon['stars']==x]\n",
    "    tokenizado_lista = tokenizado_df.review_entero_tk.tolist()\n",
    "\n",
    "    lista = [x for l in tokenizado_lista for x in l]\n",
    "\n",
    "    frecuencia_palabras = Counter(lista)\n",
    "    palabras_comunes = frecuencia_palabras.most_common()\n",
    "    \n",
    "    print(f'5 palabras más comunes para críticas de {x} estrellas')\n",
    "    df_frec = pd.DataFrame(palabras_comunes, columns = ['Palabras', 'Frecuencia'])\n",
    "    print(df_frec.head(5))\n",
    "    print('-------------')\n",
    "    \n",
    "    fig,(ax1,ax2) = plt.subplots(2,1,figsize=(800,400))\n",
    "    ax1 = plt.subplot(211)\n",
    "    u_string=(\" \").join(lista)\n",
    "    wc = WordCloud(max_words = 50,width=800,height=400).generate(u_string)\n",
    "    plt.imshow(wc)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f'Nube de palabras en críticas de {x} estrellas', fontsize=100)\n",
    "\n",
    "    \n",
    "    ax2 = sns.barplot(ax=ax2,x = df_frec.iloc[:20].Palabras, y = df_frec.iloc[:20].Frecuencia)\n",
    "    ax2.set(xlabel='Frecuencias', ylabel='Palabras')\n",
    "    ax2.set_title(f'Frecuencia de palabras en críticas de {x} estrellas')\n",
    "    plt.show()\n",
    "    print('-------------')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS_Proyecto_03_NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
