{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2GRQnxMzISE_"
   },
   "source": [
    "# Proyecto 03 - Procesamiento del Lenguaje Natural\n",
    "\n",
    "## Dataset: The Multilingual Amazon Reviews Corpus\n",
    "\n",
    "**Recuerda descargar el dataset de [aquí](https://github.com/kang205/SASRec). Es un archivo .zip que contiene tres documentos. Más información sobre el dataset [aquí](https://registry.opendata.aws/amazon-reviews-ml/). Es importante que tengas en cuenta la [licencia](https://docs.opendata.aws/amazon-reviews-ml/license.txt) de este dataset.**\n",
    "\n",
    "### Exploración de datos y Procesamiento del Lenguaje Natural\n",
    "\n",
    "Dedícale un buen tiempo a hacer un Análisis Exploratorio de Datos. Considera que hasta que no hayas aplicado las herramientas de Procesamiento del Lenguaje Natural vistas, será difícil completar este análisis. Elige preguntas que creas que puedas responder con este dataset. Por ejemplo, ¿qué palabras están asociadas a calificaciones positivas y qué palabras a calificaciones negativas?\n",
    "\n",
    "### Machine Learning\n",
    "\n",
    "Implementa un modelo que, dada la crítica de un producto, asigne la cantidad de estrellas correspondiente. **Para pensar**: ¿es un problema de Clasificación o de Regresión?\n",
    "\n",
    "1. Haz todas las transformaciones de datos que consideres necesarias. Justifica.\n",
    "1. Evalúa de forma apropiada sus resultados. Justifica la métrica elegida.\n",
    "1. Elige un modelo benchmark y compara tus resultados con este modelo.\n",
    "1. Optimiza los hiperparámetros de tu modelo.\n",
    "1. Intenta responder la pregunta: ¿Qué información está usando el modelo para predecir?\n",
    "\n",
    "**Recomendación:** si no te resulta conveniente trabajar en español con NLTK, te recomendamos que explores la librería [spaCy](https://spacy.io/).\n",
    "\n",
    "### Para pensar, investigar y, opcionalmente, implementar\n",
    "1. ¿Valdrá la pena convertir el problema de Machine Learning en un problema binario? Es decir, asignar únicamente las etiquetas Positiva y Negativa a cada crítica y hacer un modelo que, en lugar de predecir las estrellas, prediga esa etiqueta. Pensar en qué situación puede ser útil. ¿Esperas que el desempeño sea mejor o peor?\n",
    "1. ¿Hay algo que te gustaría investigar o probar?\n",
    "\n",
    "### **¡Tómate tiempo para investigar y leer mucho!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1GFwraSISFB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('dataset_es_dev.json',lines=True)\n",
    "df_test = pd.read_json('dataset_es_test.json',lines=True)\n",
    "df_train = pd.read_json('dataset_es_train.json',lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A - Exploración de datos y Procesamiento del Lenguaje Natural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto el dataset de formación como el de prueba cuentan con <code>5000 reviews</code>, mientras que el de entrenamiento posee <code>200.000 instancias</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df_test.shape)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos cuentan con 7 atributos:\n",
    "- ID de reseña\n",
    "- ID de producto\n",
    "- ID de evaluador\n",
    "- Estrellas\n",
    "- Cuerpo de reseña\n",
    "- Título de reseña\n",
    "- Idioma\n",
    "- Categoría de producto\n",
    "\n",
    "Ninguno de los cuales posee valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "print(df_test.info())\n",
    "print(df_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La totalidad de las reseñas se encuentran en idioma español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['language'].unique())\n",
    "print(df_test['language'].unique())\n",
    "print(df_train['language'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que para explorar el dataset completo resulta difícil trabajar con los 3 por separado, los concatenaré a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon = pd.concat([df,df_test,df_train],axis=0)\n",
    "df_amazon.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedo observar del siguiente gráfico que cada puntaje posee la misma cantidad de reseñas asociadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'stars', data = df_amazon)\n",
    "plt.ylabel('Cantidad de reseñas')\n",
    "plt.xlabel('Puntaje (estrellas)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Existen',str(len(df_amazon['product_category'].unique())),'categorías únicas en el presente dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que predominan las reseñas de productos línea **hogar** e **inalámbricos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "sns.countplot(y = 'product_category', \n",
    "              data = df_amazon,  \n",
    "              order = df_amazon.product_category.value_counts().index)\n",
    "plt.ylabel('Categoría',size=13)\n",
    "plt.xlabel('Cantidad de reviews')\n",
    "plt.tick_params(axis='y', labelsize=13)\n",
    "plt.title('Categorías de los diferentes productos', size=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lematización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = es_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon['review_lemm'] = '' #inicia con string vacio\n",
    "stop_words = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon['review_entero'] = df_amazon['review_body']+ ' ' + df_amazon['review_title']\n",
    "df_amazon.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, tokenizo la reseña. Esto es, separo las palabras en comas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df_amazon.shape[0]):\n",
    "    review_tratado = df_amazon.iloc[i].review_entero #seleccionar el titular\n",
    "    review_tratado = tokenizer.tokenize(review_tratado) # Tokenizar con RegexpTokenizer\n",
    "    review_tratado = [word for word in review_tratado if word not in stopwords] # Filtrar por stopwords\n",
    "    review_tratado.append(review_tratado) #agregar el resultado a la lista\n",
    "\n",
    "print(review_tratado)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS_Proyecto_03_NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
